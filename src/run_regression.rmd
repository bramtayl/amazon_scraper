---
title: "Shadow price"
output:
  html_document
---

```{r, setup}
knitr::opts_knit$set(root.dir = '/home/brandon/amazon_scraper')
```

I looked into running a ordinal regression with rstan, nested within each search.
Unfortunately, I don't think that is feasible.
The rank transformation is discrete, and removes too much information.

So instead, I transformed rankings (with 1 being the best) to negative log rankings.
I did this both for search rankings and best seller rankings.
I logged because the difference between the top few spots matters most.
I used the negative value to make interpretation easier.
A negative log ranking that is larger, that is, closer to 0, is "better", that is, closer to the #1 spot.

First, I predicted the negative log best seller rank.
Here, I added random effects for the best seller category.

```{r}
library(readr)
library(dplyr, warn.conflicts = FALSE)
library(Matrix)
library(lme4)
library(pander)

product_data <-
    read_csv("results/products/products.csv", show_col_types = FALSE) %>%
    mutate(
        log_unit_price = ifelse(unit_price > 0, log(unit_price), NA)
    ) %>%
    inner_join(
        read_csv(
            "results/products/product_url_data.csv",
            show_col_types = FALSE
        ) %>%
            rename(search_rank = rank),
        by = "product_id"
    ) %>%
    inner_join(
        read_csv("inputs/queries.csv", show_col_types = FALSE) %>%
            mutate(search_id = paste0(department, "-", query)),
        by = "search_id"
    ) %>%
    inner_join(
        read_csv(
            "results/products/best_sellers.csv",
            show_col_types = FALSE
        ) %>%
            # use the best seller rank from the most general category
            filter(order == 1) %>%
            mutate(
                negative_log_best_seller_rank = -log(best_seller_rank)
            ),
        by = "product_id"
    ) %>%
    inner_join(
        read_csv(
            "results/products/relevance.csv",
            show_col_types = FALSE
        ) %>%
            # normalize this for easier interpretation
            mutate(scaled_relevance_score = scale(score)),
        by = c("product_id", "query")
    )

best_seller_rank_model <- lmer(
    negative_log_best_seller_rank ~
        average_rating +
        climate_friendly +
        free_returns +
        log_unit_price +
        small_business +
        subscription_available +

        (1 | best_seller_category),
    data = product_data
)

summary(product_data)
```

Second, I predicted the negative log search rank.
I used the negative log best seller rank as one predictor.
Here, I added random effects for the search.

```{r}
complete_search_data <-
    product_data %>%
    select(
        # same predictors we used for best seller rank
        # these mostly have indirect effects, but control for them anyways
        average_rating,
        climate_friendly,
        free_returns,
        log_unit_price,
        small_business,
        subscription_available,

        # these predictors have direct effects on search rankings
        amazon_brand,
        negative_log_best_seller_rank,
        scaled_relevance_score,
        sponsored,

        # outcome
        search_rank,
        # random effect
        search_id,
    ) %>%
    filter(complete.cases(.)) %>%
    arrange(search_id, search_rank) %>%
    group_by(search_id) %>%
    mutate(negative_log_search_rank = -log(seq_len(n()))) %>%
    ungroup()

search_rank_model <- lmer(
    negative_log_search_rank ~
        average_rating +
        climate_friendly +
        free_returns +
        log_unit_price +
        small_business +
        subscription_available +

        amazon_brand +
        negative_log_best_seller_rank +
        scaled_relevance_score +
        sponsored +

        (1 | search_id),
    data = complete_search_data
)

summary(search_rank_model)
```

Amazon seems to mostly ignore product characteristics when ranking search results.
Instead, Amazon just uses sales data, and sales in turn are affected by product characteristics.

Now, calculate a shadow price.

$$-\log(\text{best_seller_rank}) = \beta_1 \log(\text{unit_price}) + \ldots$$

Implicitly derive

$$- \frac{1}{\text{best_seller_rank}} d(\text{best_seller_rank}) = \beta_1 \frac{1}{\text{unit_price}} d(\text{unit_price}) + \ldots$$

So

$$\frac{\partial(\text{best_seller_rank})}{\partial(\text{unit_price})} = - \beta_1 \frac{\text{best_seller_rank}}{\text{unit_price}}$$

Now look at search rank.

$$-\log(\text{search_rank}) = \gamma_1 \text{sponsored} + \gamma_2 (-\log(\text{best_seller_rank})) + \ldots$$

Implicitly derive

$$- \frac{1}{\text{search_rank}} d(\text{search_rank}) = \gamma_1 d(\text{sponsored}) - \gamma_2 \frac{1}{\text{best_seller_rank}} d(\text{best_seller_rank}) + \ldots$$

So
 
$$\frac{\partial (\text{search_rank})}{\partial (\text{sponsored})} = - \gamma_1 \text{search_rank}$$

$$\frac{\partial (\text{search_rank})}{\partial (\text{best_seller_rank})} = \gamma_2 \frac{\text{search_rank}}{\text{best_seller_rank}}$$

Use the chain rule

$$\frac{\partial (\text{search_rank})}{\partial (\text{unit_price})} =  \frac{\partial (\text{search_rank})}{\partial (\text{best_seller_rank})} \frac{\partial(\text{best_seller_rank})}{\partial(\text{unit_price})} = -\beta_1 \gamma_2 \frac{\text{search_rank}}{\text{unit_price}}$$

Finally, here is the shadow price:

$$-\frac{ \frac{\partial \text{search_rank}}{\partial \text{sponsored}}}{ \frac{\partial (\text{search_rank})}{\partial (\text{unit_price})}} = - \frac{\beta_1 \gamma_2}{\gamma_1} \text{unit_price}$$

Since the shadow price is proportional to price, I will use the term shadow "proportion" to refer to this proportion.

Here, I ran a mini-simulation to calculate a confidence interval for the shadow proportion.

The standard error of coefficients should be roughly proportional to the square root of the number of samples.

First, I'll simulate the confidence interval with the existing standard errors.

```{r}
get_shadow_interval  <- function(
    best_seller_rank_model,
    search_rank_model,
    scale_factor = 1,
    number_of_simulations = 10000,
    alpha = 0.025
) {
    search_coefficients <- summary(search_rank_model)$coefficients
    best_seller_coefficients <- summary(best_seller_rank_model)$coefficients
    quantile(
        -(
            best_seller_coefficients["log_unit_price", "Estimate"] +
            rnorm(number_of_simulations) *
            best_seller_coefficients["log_unit_price", "Std. Error"] /
            sqrt(scale_factor)
        ) * (
            search_coefficients["negative_log_best_seller_rank", "Estimate"] +
            rnorm(number_of_simulations) *
            search_coefficients[
                "negative_log_best_seller_rank",
                "Std. Error"
            ] / 
            sqrt(scale_factor)
        ) /
        (
            search_coefficients["sponsoredTRUE", "Estimate"] +
            rnorm(number_of_simulations) *
            search_coefficients["sponsoredTRUE", "Std. Error"] /
            sqrt(scale_factor)
        ),
        probs = c(alpha, 1 - alpha)
    )
}

pander(get_shadow_interval (best_seller_rank_model, search_rank_model))
```

This is saying that the shadow price of sponsorship is between 3.3% and 6.6% of the price of the product.

This seems comparatively small; we could probably argue that Amazon is ripping off its sellers.

If we collect 10X more data, this is roughly the size of the confidence interval we can expect:

```{r}
pander(get_shadow_interval (best_seller_rank_model, search_rank_model, scale_factor = 10))
```

That seems probably sufficient?