---
title: "Shadow price"
output:
  html_document
---

```{r, setup}

knitr::opts_knit$set(root.dir = '/home/brandon/amazon_scraper')
```

Combine the data to export to stata.

```{r}
library(readr)
library(dplyr, warn.conflicts = FALSE)
library(Matrix)
library(lme4)
library(mlogit)
library(pander)

product_data <-
    read_csv("results/products/products.csv", show_col_types = FALSE) %>%
    mutate(
        log_unit_price = ifelse(unit_price > 0, log(unit_price), NA),
        discount_percent = (list_price - price) / price,
        coupon_percent = coupon_amount / price,
        standard_shipping_date_range = 
            standard_shipping_date_end - standard_shipping_date_start,
        standard_shipping_expected_date = 
            standard_shipping_date_start + standard_shipping_date_range / 2
    ) %>%
    inner_join(
        read_csv(
            "results/products/product_url_data.csv",
            show_col_types = FALSE
        ) %>%
            rename(search_rank = rank),
        by = "ASIN"
    ) %>%
    inner_join(
        read_csv("inputs/queries.csv", show_col_types = FALSE) %>%
            mutate(search_id = paste0(department, "-", query)),
        by = "search_id"
    ) %>%
    inner_join(
        read_csv(
            "results/products/best_sellers.csv",
            show_col_types = FALSE
        ) %>%
            # use the best seller rank from the most general category
            filter(order == 1) %>%
            mutate(
                negative_log_best_seller_rank = -log(best_seller_rank)
            ),
        by = "ASIN"
    ) %>%
    inner_join(
        read_csv(
            "results/products/relevance.csv",
            show_col_types = FALSE
        ) %>%
            # normalize this for easier interpretation
            mutate(scaled_relevance_score = scale(score)[,1]),
        by = c("ASIN", "query")
    ) %>%
    select(
        amazon_brand,
        answered_questions,
        amazons_choice,
        average_rating,
        best_seller_category,
        best_seller_rank,
        climate_friendly,
        coupon_percent,
        department,
        discount_percent,
        fakespot_ranking,
        free_prime_shipping,
        free_returns,
        limited_stock,
        log_unit_price,
        negative_log_best_seller_rank,
        new_seller,
        number_of_ratings,
        new_seller,
        product_department,
        return_within_days,
        scaled_relevance_score,
        search_id,
        search_rank,
        ships_from_amazon,
        small_business,
        sold_by_amazon,
        sponsored,
        standard_shipping_date_range,
        standard_shipping_expected_date,
        subscribe_coupon,
        subscription_available,
        unit,
        unit_price,
        one_star_percent,
        two_star_percent,
        three_star_percent,
        four_star_percent,
        five_star_percent
    ) %>%
    filter(complete.cases(.)) %>%
    arrange(best_seller_category, best_seller_rank) %>%
    group_by(best_seller_category) %>%
    mutate(best_seller_rank = seq_len(n())) %>%
    ungroup %>%
    arrange(search_id, search_rank) %>%
    group_by(search_id) %>%
    mutate(search_rank = seq_len(n())) %>%
    ungroup %>%
    write_csv("complete_search_data.csv")
```

Calculate a shadow price.

$$-\log(\text{best_seller_rank}) = \beta_1 \log(\text{unit_price}) + \ldots$$

Implicitly derive

$$- \frac{1}{\text{best_seller_rank}} d(\text{best_seller_rank}) = \beta_1 \frac{1}{\text{unit_price}} d(\text{unit_price}) + \ldots$$

So

$$\frac{\partial(\text{best_seller_rank})}{\partial(\text{unit_price})} = - \beta_1 \frac{\text{best_seller_rank}}{\text{unit_price}}$$

Now look at search rank.

$$-\log(\text{search_rank}) = \gamma_1 \text{sponsored} + \gamma_2 (-\log(\text{best_seller_rank})) + \ldots$$

Implicitly derive

$$- \frac{1}{\text{search_rank}} d(\text{search_rank}) = \gamma_1 d(\text{sponsored}) - \gamma_2 \frac{1}{\text{best_seller_rank}} d(\text{best_seller_rank}) + \ldots$$

So
 
$$\frac{\partial (\text{search_rank})}{\partial (\text{sponsored})} = - \gamma_1 \text{search_rank}$$

$$\frac{\partial (\text{search_rank})}{\partial (\text{best_seller_rank})} = \gamma_2 \frac{\text{search_rank}}{\text{best_seller_rank}}$$

Use the chain rule

$$\frac{\partial (\text{search_rank})}{\partial (\text{unit_price})} =  \frac{\partial (\text{search_rank})}{\partial (\text{best_seller_rank})} \frac{\partial(\text{best_seller_rank})}{\partial(\text{unit_price})} = -\beta_1 \gamma_2 \frac{\text{search_rank}}{\text{unit_price}}$$

Finally, here is the shadow price:

$$-\frac{ \frac{\partial \text{search_rank}}{\partial \text{sponsored}}}{ \frac{\partial (\text{search_rank})}{\partial (\text{unit_price})}} = - \frac{\beta_1 \gamma_2}{\gamma_1} \text{unit_price}$$

Since the shadow price is proportional to price, I will use the term shadow "proportion" to refer to this proportion.

Here, I ran a mini-simulation to calculate a confidence interval for the shadow proportion.

The standard error of coefficients should be roughly proportional to the square root of the number of samples.

First, I'll simulate the confidence interval with the existing standard errors.

```{r}
get_shadow_interval  <- function(
    best_seller_rank_model,
    search_rank_model,
    scale_factor = 1,
    number_of_simulations = 10000,
    alpha = 0.025
) {
    search_coefficients <- summary(search_rank_model)$coefficients
    best_seller_coefficients <- summary(best_seller_rank_model)$coefficients
    quantile(
        -(
            best_seller_coefficients["log_unit_price", "Estimate"] +
            rnorm(number_of_simulations) *
            best_seller_coefficients["log_unit_price", "Std. Error"] /
            sqrt(scale_factor)
        ) * (
            search_coefficients["negative_log_best_seller_rank", "Estimate"] +
            rnorm(number_of_simulations) *
            search_coefficients[
                "negative_log_best_seller_rank",
                "Std. Error"
            ] / 
            sqrt(scale_factor)
        ) /
        (
            search_coefficients["sponsoredTRUE", "Estimate"] +
            rnorm(number_of_simulations) *
            search_coefficients["sponsoredTRUE", "Std. Error"] /
            sqrt(scale_factor)
        ),
        probs = c(alpha, 1 - alpha)
    )
}

pander(get_shadow_interval(best_seller_rank_model, search_rank_model))
```

This is saying that the shadow price of sponsorship is between 3.3% and 6.6% of the price of the product.

This seems comparatively small; we could probably argue that Amazon is ripping off its sellers.

If we collect 10X more data, this is roughly the size of the confidence interval we can expect:

```{r}
pander(get_shadow_interval (best_seller_rank_model, search_rank_model, scale_factor = 10))
```

That seems probably sufficient?